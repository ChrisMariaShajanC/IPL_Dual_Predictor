{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPcb3iOudlaL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hRbxNRFeQIf"
      },
      "source": [
        "#**matches.csv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8bgCDuDeV7p"
      },
      "source": [
        "##Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfcQVC2iePhp"
      },
      "outputs": [],
      "source": [
        "matches=pd.read_csv('/content/matches.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkgSW1dDeoq2"
      },
      "outputs": [],
      "source": [
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lvCXkx6eqaN"
      },
      "outputs": [],
      "source": [
        "matches.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24O_9yFdesyS"
      },
      "outputs": [],
      "source": [
        "matches.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJhD1-TWexh1"
      },
      "outputs": [],
      "source": [
        "matches.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Q855Ppez-o"
      },
      "outputs": [],
      "source": [
        "matches.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX4mfvXMe24n"
      },
      "outputs": [],
      "source": [
        "matches.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSDEE2ipe40C"
      },
      "outputs": [],
      "source": [
        "matches.isna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3HizFPYe69D"
      },
      "outputs": [],
      "source": [
        "matches.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1wAQarye8j-"
      },
      "outputs": [],
      "source": [
        "matches['city'] = matches['city'].fillna('Unknown')\n",
        "matches['result_margin'] = matches['result_margin'].fillna(0)\n",
        "matches['target_runs'] = matches['target_runs'].fillna(0)\n",
        "matches['target_overs'] = matches['target_overs'].fillna(0)\n",
        "matches['player_of_match'] = matches['player_of_match'].fillna('None')\n",
        "matches['winner']=matches['winner'].fillna('Draw')\n",
        "matches['method']=matches['method'].fillna('None')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnQAmbzae_0K"
      },
      "outputs": [],
      "source": [
        "matches.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i2yln7bfDMV"
      },
      "outputs": [],
      "source": [
        "matches.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ern8_KqLfFIK"
      },
      "outputs": [],
      "source": [
        "matches.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smnPCLX0fHzb"
      },
      "outputs": [],
      "source": [
        "matches.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0lJNp2PfJa9"
      },
      "outputs": [],
      "source": [
        "pd.value_counts(matches['season'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxVNdmu4fPEh"
      },
      "source": [
        "##EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHQXaXq_fL0L"
      },
      "outputs": [],
      "source": [
        "categorical_cols = matches.select_dtypes(include='object').columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nðŸ”¹ Value Counts: {col}\")\n",
        "    print(matches[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gdCsnLgfUH3"
      },
      "outputs": [],
      "source": [
        "# Histograms for numerical features\n",
        "matches.hist(bins=30, figsize=(18, 15), color='skyblue')\n",
        "plt.suptitle(\"Histograms of Numerical Features\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlaQl0vjfWJc"
      },
      "outputs": [],
      "source": [
        "# Bar plots for categorical variables\n",
        "for col in ['match_type', 'toss_decision', 'result', 'super_over']:\n",
        "    sns.countplot(x=col, data=matches)\n",
        "    plt.title(f\"Count Plot of {col}\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb9WCyhRfZNH"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "corr_matrix = matches.select_dtypes(include=['float64', 'int64']).corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap of Numerical Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4-qbjNLfe3n"
      },
      "source": [
        "##Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYBTkxfwfcfe"
      },
      "outputs": [],
      "source": [
        "numeric_cols = matches.select_dtypes(include='number').columns\n",
        "\n",
        "# Plot boxplots for each numerical column in a grid\n",
        "n_cols = 3\n",
        "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
        "\n",
        "plt.figure(figsize=(n_cols*5, n_rows*4))\n",
        "\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    sns.boxplot(y=matches[col])\n",
        "    plt.title(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTgB8haafnYZ"
      },
      "outputs": [],
      "source": [
        "def iqr_trim(s, k=1.5):\n",
        "    # loop until nothing changes\n",
        "    while True:\n",
        "        q1, q3 = s.quantile([0.25, 0.75])\n",
        "        iqr     = q3 - q1\n",
        "        lb, ub  = q1 - k*iqr, q3 + k*iqr\n",
        "        new_s   = s.where((s >= lb) & (s <= ub))\n",
        "        if new_s.equals(s):          # nothing else got removed\n",
        "            return new_s.dropna()    # done\n",
        "        s = new_s.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc8CsFgAfbFx"
      },
      "outputs": [],
      "source": [
        "ID = matches['id']\n",
        "ID = pd.DataFrame(ID)\n",
        "ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BErsffC3fp-8"
      },
      "outputs": [],
      "source": [
        "matches.drop(['id'], axis=1, inplace=True)\n",
        "matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZRXDFKefuMm"
      },
      "source": [
        "##Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXSMGmSffsL4"
      },
      "outputs": [],
      "source": [
        "matches.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrcdhjf1fzqQ"
      },
      "source": [
        "###Frequency Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UgOyllZfyht"
      },
      "outputs": [],
      "source": [
        "city_freq = matches['city'].value_counts().to_dict()\n",
        "matches['city'] = matches['city'].map(city_freq)\n",
        "player_of_match_freq = matches['player_of_match'].value_counts().to_dict()\n",
        "matches['player_of_match'] = matches['player_of_match'].map(player_of_match_freq)\n",
        "umpire1_freq = matches['umpire1'].value_counts().to_dict()\n",
        "matches['umpire1'] = matches['umpire1'].map(umpire1_freq)\n",
        "umpire2_freq = matches['umpire2'].value_counts().to_dict()\n",
        "matches['umpire2'] = matches['umpire2'].map(umpire2_freq)\n",
        "venue_freq = matches['venue'].value_counts().to_dict()\n",
        "matches['venue'] = matches['venue'].map(venue_freq)\n",
        "date_freq = matches['date'].value_counts().to_dict()\n",
        "matches['date'] = matches['date'].map(date_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3xQ9TElf5_L"
      },
      "outputs": [],
      "source": [
        "matches.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unE3xAMyf9dN"
      },
      "source": [
        "###Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmhhsl_Bf8bG"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(matches['winner'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwsNR6URgDeU"
      },
      "outputs": [],
      "source": [
        "matches['team1']=le.fit_transform(matches['team1'])\n",
        "matches['team2']=le.fit_transform(matches['team2'])\n",
        "matches['toss_winner']=le.fit_transform(matches['toss_winner'])\n",
        "matches['match_type']=le.fit_transform(matches['match_type'])\n",
        "matches['winner']=le.fit_transform(matches['winner'])\n",
        "matches['result']=le.fit_transform(matches['result'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDiR621LgFnt"
      },
      "outputs": [],
      "source": [
        "matches.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTteogvegKxh"
      },
      "source": [
        "###One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c9y332ggIL5"
      },
      "outputs": [],
      "source": [
        "matches=pd.get_dummies(matches,dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgkCpYBSgSGI"
      },
      "outputs": [],
      "source": [
        "matches.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz4IYV0oge7u"
      },
      "source": [
        "##Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id7uzVnsgUyB"
      },
      "outputs": [],
      "source": [
        "matches.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuoz8HPhiGV1"
      },
      "outputs": [],
      "source": [
        "matches.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-WcdDisiH-w"
      },
      "outputs": [],
      "source": [
        "matches.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKZr8XKfiKTF"
      },
      "outputs": [],
      "source": [
        "matches.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJY0QbdQiMWl"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLVR9GkGiOgt"
      },
      "outputs": [],
      "source": [
        "matches['season']=scaler.fit_transform(matches[['season']])\n",
        "matches['city']=scaler.fit_transform(matches[['city']])\n",
        "matches['match_type']=scaler.fit_transform(matches[['match_type']])\n",
        "matches['player_of_match']=scaler.fit_transform(matches[['player_of_match']])\n",
        "matches['venue']=scaler.fit_transform(matches[['venue']])\n",
        "matches['team1']=scaler.fit_transform(matches[['team1']])\n",
        "matches['team2']=scaler.fit_transform(matches[['team2']])\n",
        "matches['toss_winner']=scaler.fit_transform(matches[['toss_winner']])\n",
        "matches['result_margin']=scaler.fit_transform(matches[['result_margin']])\n",
        "matches['target_runs']=scaler.fit_transform(matches[['target_runs']])\n",
        "matches['target_overs']=scaler.fit_transform(matches[['target_overs']])\n",
        "matches['umpire1']=scaler.fit_transform(matches[['umpire1']])\n",
        "matches['umpire2']=scaler.fit_transform(matches[['umpire2']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37B-acy-iQO_"
      },
      "outputs": [],
      "source": [
        "matches.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZeeJNPiiSlL"
      },
      "outputs": [],
      "source": [
        "matches.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvUg3H_WiWiO"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-1fgNb-iUpy"
      },
      "outputs": [],
      "source": [
        "features = ['season', 'city', 'match_type', 'player_of_match', 'venue',\n",
        "            'team1', 'team2', 'toss_winner', 'toss_decision_bat','toss_decision_field', 'umpire1', 'umpire2']\n",
        "X = matches[features]\n",
        "y = matches['winner']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2elFuO3Ai9SR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGx5geRsi_0f"
      },
      "source": [
        "###Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9YI277bi-7r"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "results = []\n",
        "\n",
        "results.append((\"Logistic Regression\", acc_lr, None, lr))\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"\\n=== Classification Report (Logistic Regression) ===\")\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALt5FmNNjiUD"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts72Ae0xjctk"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "acc_rf = accuracy_score(y_test, rf.predict(X_test))\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"\\n=== Random Forest ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RykRdhvOj4Vi"
      },
      "source": [
        "###SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVKFYbmuj6vL"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Train SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "results.append((\"SVM\", acc_svm, None, svm))\n",
        "\n",
        "# Output\n",
        "print(\"\\n=== Support Vector Machine ===\")\n",
        "print(\"Accuracy:\", acc_svm)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g87ypUOxj94F"
      },
      "source": [
        "###KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47TeObQajmzZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
        "results.append((\"KNN\", acc_knn, None, knn))\n",
        "print(\"\\n=== K-Nearest Neighbors ===\")\n",
        "print(\"Accuracy:\", acc_knn)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF4tSTmCkDGf"
      },
      "source": [
        "###Navie Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KSaYWX7kAux"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Train Naive Bayes model\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
        "results.append((\"Naive Bayes\", acc_nb, None, nb))\n",
        "\n",
        "# Output\n",
        "print(\"\\n=== Naive Bayes ===\")\n",
        "print(\"Accuracy:\", acc_nb)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDFn9EEzkPuD"
      },
      "source": [
        "###XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PojxMkykNlq"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Train the XGBoost model\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_gb = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
        "results.append((\"XGBoost\", acc_gb, None, model))\n",
        "\n",
        "# Output\n",
        "print(\"\\n=== Gradient Boosting ===\")\n",
        "print(\"Accuracy:\", acc_gb)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_gb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfVpZLSkhxm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU3ZaJukkiEQ"
      },
      "source": [
        "###Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9MZy0RHkXeW"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Train Decision Tree model\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
        "results.append((\"Decision Tree\", acc_dt, None, dt))\n",
        "\n",
        "# Output\n",
        "print(\"\\n=== Decision Tree ===\")\n",
        "print(\"Accuracy:\", acc_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRU0_rXqkqWi"
      },
      "source": [
        "###Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg7NaWUVkns6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_gbc = gbc.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc_gbc = accuracy_score(y_test, y_pred_gbc)\n",
        "results.append((\"Gradient Boosting\", acc_gbc, None, gbc))\n",
        "\n",
        "# Output\n",
        "print(\"\\n=== Gradient Boosting Classifier ===\")\n",
        "print(\"Accuracy:\", acc_gbc)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_gbc))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHAhswF7kyhJ"
      },
      "outputs": [],
      "source": [
        "unique_results = {}\n",
        "for name, acc, _, model in results:\n",
        "    unique_results[name] = (acc, model)\n",
        "print(\"=== Model Accuracy Comparison ===\")\n",
        "print(f\"{'Model':<20} {'Accuracy':<10}\")\n",
        "for name, (acc, _) in unique_results.items():\n",
        "    print(f\"{name:<20} {acc:<10.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwqQa-P8k9Xb"
      },
      "source": [
        "##Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpTvfxVsk3DH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "models = {\n",
        "    \"XGBoost\": model,\n",
        "    \"Gradient Boosting\": gbc\n",
        "}\n",
        "\n",
        "xgb_pred = models[\"XGBoost\"].predict(X_test)\n",
        "gb_pred = models[\"Gradient Boosting\"].predict(X_test)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, xgb_pred, ax=axs[0], cmap='Blues')\n",
        "axs[0].set_title(\"XGBoost Confusion Matrix\")\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, gb_pred, ax=axs[1], cmap='Greens')\n",
        "axs[1].set_title(\"Gradient Boosting Confusion Matrix\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfjvbXpLlEm0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
        "print(\"Mean Accuracy:\", np.mean(scores))\n",
        "print(\"Standard Deviation:\", np.std(scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTnsw7G4lNxg"
      },
      "source": [
        "##HPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V-UJGZ4lMSM"
      },
      "outputs": [],
      "source": [
        "# ðŸ“¦ Import libraries\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# âœ… Step 1: Prepare your dataset (replace X and y with your data)\n",
        "# For example:\n",
        "# X = your_features_dataframe\n",
        "# y = your_target_series\n",
        "\n",
        "# ðŸ§ª Step 2: Use small subset for tuning to reduce memory usage\n",
        "X_sample, _, y_sample, _ = train_test_split(X, y, train_size=0.1, stratify=y, random_state=42)\n",
        "\n",
        "# ðŸ§  Step 3: Define lightweight XGBoost model\n",
        "xgb = XGBClassifier(\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='hist',     # Fast and memory-efficient\n",
        "    n_jobs=1,               # Avoid using all CPU cores (prevents crashes)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ðŸ”§ Step 4: Simplified hyperparameter search space\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 0.2],\n",
        "    'reg_alpha': [0, 1],\n",
        "    'reg_lambda': [0, 1],\n",
        "}\n",
        "\n",
        "# ðŸ” Step 5: RandomizedSearchCV (reduced iterations and CV folds)\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,             # Fewer combinations = faster\n",
        "    scoring='accuracy',\n",
        "    cv=2,                  # Less memory than 5-fold\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=1               # Single-threaded to avoid memory spike\n",
        ")\n",
        "\n",
        "# ðŸƒ Step 6: Fit on sample dataset (no early_stopping needed on tiny set)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# âœ… Step 7: Output best results\n",
        "print(\"âœ… Best Parameters:\", random_search.best_params_)\n",
        "print(\"âœ… Best Accuracy on Sample:\", random_search.best_score_)\n",
        "\n",
        "# ðŸ Step 8: Train final model on full data using best params\n",
        "best_model = random_search.best_estimator_\n",
        "best_model.fit(X, y)\n",
        "\n",
        "# ðŸ’¾ Step 9: Save final model\n",
        "joblib.dump(best_model, \"xgb_best_model.pkl\")\n",
        "print(\"âœ… Model saved as 'xgb_best_model.pkl'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzLf3eB-ldqO"
      },
      "source": [
        "##Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM05DCeToQvX"
      },
      "outputs": [],
      "source": [
        "city_freq = matches['city'].value_counts(normalize=True).to_dict()\n",
        "player_of_match_freq = matches['player_of_match'].value_counts(normalize=True).to_dict()\n",
        "umpire1_freq = matches['umpire1'].value_counts(normalize=True).to_dict()\n",
        "umpire2_freq = matches['umpire2'].value_counts(normalize=True).to_dict()\n",
        "venue_freq = matches['venue'].value_counts(normalize=True).to_dict()\n",
        "date_freq = matches['date'].value_counts(normalize=True).to_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy11fiply8Sn"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(city_freq, \"city_freq.pkl\")\n",
        "joblib.dump(player_of_match_freq, \"player_of_match_freq.pkl\")\n",
        "joblib.dump(umpire1_freq, \"umpire1_freq.pkl\")\n",
        "joblib.dump(umpire2_freq, \"umpire2_freq.pkl\")\n",
        "joblib.dump(venue_freq, \"venue_freq.pkl\")\n",
        "joblib.dump(date_freq, \"date_freq.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKXjpAXCzEln"
      },
      "outputs": [],
      "source": [
        "city_freq = joblib.load(\"city_freq.pkl\")\n",
        "player_of_match_freq = joblib.load(\"player_of_match_freq.pkl\")\n",
        "umpire1_freq = joblib.load(\"umpire1_freq.pkl\")\n",
        "umpire2_freq = joblib.load(\"umpire2_freq.pkl\")\n",
        "venue_freq = joblib.load(\"venue_freq.pkl\")\n",
        "date_freq = joblib.load(\"date_freq.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTbb18_hzFDE"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "best_xgb_model = joblib.load(\"xgb_best_model.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Assuming y contains the winner team names\n",
        "winner_encoder = LabelEncoder()\n",
        "y_encoded = winner_encoder.fit_transform(y)  # `y` = match['winner']\n",
        "joblib.dump(winner_encoder, 'winner_encoder.pkl')\n"
      ],
      "metadata": {
        "id": "yLuDGHGOG0fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw7n2xx-mhI0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load the label encoder for the 'winner' column\n",
        "try:\n",
        "    winner_encoder = joblib.load('winner_encoder.pkl')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'winner_encoder.pkl' not found. Please ensure the encoder was saved correctly.\")\n",
        "\n",
        "    exit()\n",
        "\n",
        "new_match = {\n",
        "    'season': 2023,\n",
        "    'city': 'Delhi',\n",
        "    'date': '2023-04-15',\n",
        "    'match_type': 'T20',\n",
        "    'player_of_match': 'David Warner',\n",
        "    'venue': 'Arun Jaitley Stadium',\n",
        "    'team2': 'Delhi Capitals',\n",
        "    'team1': 'Mumbai Indians',\n",
        "    'toss_winner': 'Mumbai Indians',\n",
        "    'result': 'normal',\n",
        "    'result_margin': 5,\n",
        "    'target_runs': 175,\n",
        "    'target_overs': 20,\n",
        "    'umpire1': 'Chris Gaffaney',\n",
        "    'umpire2': 'Nitin Menon',\n",
        "    'toss_decision_bat': 0,\n",
        "    'toss_decision_field': 1,\n",
        "    'super_over_N': 1,\n",
        "    'super_over_Y': 0,\n",
        "    'method_D/L': 0,\n",
        "    'method_None': 1\n",
        "}\n",
        "\n",
        "\n",
        "new_df = pd.DataFrame([new_match])\n",
        "\n",
        "new_df['city'] = new_df['city'].map(city_freq).fillna(0)\n",
        "new_df['player_of_match'] = new_df['player_of_match'].map(player_of_match_freq).fillna(0)\n",
        "new_df['umpire1'] = new_df['umpire1'].map(umpire1_freq).fillna(0)\n",
        "new_df['umpire2'] = new_df['umpire2'].map(umpire2_freq).fillna(0)\n",
        "new_df['venue'] = new_df['venue'].map(venue_freq).fillna(0)\n",
        "new_df['date'] = new_df['date'].map(date_freq).fillna(0)\n",
        "\n",
        "\n",
        "new_df_encoded = pd.get_dummies(new_df,dtype=int)\n",
        "missing_cols = set(X.columns) - set(new_df_encoded.columns)\n",
        "for col in missing_cols:\n",
        "    new_df_encoded[col] = 0\n",
        "new_df_encoded = new_df_encoded[X.columns]\n",
        "\n",
        "y_pred = best_xgb_model.predict(new_df_encoded)\n",
        "probs = best_xgb_model.predict_proba(new_df_encoded)[0]\n",
        "predicted_team = winner_encoder.inverse_transform(y_pred)[0]\n",
        "\n",
        "team1 = new_match['team1']\n",
        "team2 = new_match['team2']\n",
        "label_classes = list(winner_encoder.classes_)\n",
        "\n",
        "if predicted_team == team1 or predicted_team == team2:\n",
        "    print(\"Winning Team:\", predicted_team)\n",
        "else:\n",
        "    try:\n",
        "        team1_index = label_classes.index(team1)\n",
        "    except ValueError:\n",
        "        team1_index = None\n",
        "\n",
        "    try:\n",
        "        team2_index = label_classes.index(team2)\n",
        "    except ValueError:\n",
        "        team2_index = None\n",
        "\n",
        "    if team1_index is not None and team2_index is not None:\n",
        "\n",
        "        winning_team = team1 if probs[team1_index] > probs[team2_index] else team2\n",
        "        print(\"Winning Team:\", winning_team)\n",
        "    else:\n",
        "        winning_team =team2\n",
        "        print(\"Winning Team:\", winning_team)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqhoooP36NTr"
      },
      "source": [
        "##Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H1tLbJey3xsh"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlya-uAb6TAI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Load the data\n",
        "matches = pd.read_csv(\"matches.csv\")\n",
        "\n",
        "# 2. Drop rows with missing values in required columns\n",
        "matches.dropna(subset=['team1', 'team2', 'toss_winner', 'toss_decision',\n",
        "                       'winner', 'venue', 'season', 'city'], inplace=True)\n",
        "\n",
        "# 3. Group rare teams as \"Other\"\n",
        "win_counts = matches['winner'].value_counts()\n",
        "rare_teams = win_counts[win_counts < 20].index\n",
        "matches['winner_grouped'] = matches['winner'].apply(lambda x: 'Other' if x in rare_teams else x)\n",
        "\n",
        "# 4. Define features and target\n",
        "features = ['team1', 'team2', 'toss_winner', 'toss_decision', 'venue', 'season', 'city']\n",
        "X = matches[features]\n",
        "y = matches['winner_grouped']\n",
        "\n",
        "# 5. Encode target\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# 6. One-hot encode categorical features\n",
        "column_transformer = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), features)\n",
        "], sparse_threshold=0)\n",
        "\n",
        "X_encoded = column_transformer.fit_transform(X)\n",
        "\n",
        "# 7. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# 8. Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# 9. Build the model\n",
        "model = Sequential([\n",
        "    Dense(256, input_shape=(X_encoded.shape[1],), activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 10. Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 11. Evaluate on test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nâœ… Final Test Accuracy: {accuracy:.4f} - Loss: {loss:.4f}\")\n",
        "\n",
        "# 12. Classification report\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(\"\\nðŸ“‹ Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# 13. Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "disp.plot(xticks_rotation='vertical', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix: Match Winner Prediction\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOj0b_PA6Wmb"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"âœ… Matches.csv - Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1tQ48Lm6qC_"
      },
      "source": [
        "#**deliveries.csv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ4AQRbI60Tg"
      },
      "source": [
        "##Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaABaqCY6m2W"
      },
      "outputs": [],
      "source": [
        "deliveries=pd.read_csv('/content/deliveries.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8wAwHYU6eXA"
      },
      "outputs": [],
      "source": [
        "deliveries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnrIGsQg7F-7"
      },
      "outputs": [],
      "source": [
        "deliveries.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDI2GoyJ7IVW"
      },
      "outputs": [],
      "source": [
        "deliveries.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTRtjsET7KT7"
      },
      "outputs": [],
      "source": [
        "deliveries.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmphKrdm7Me3"
      },
      "outputs": [],
      "source": [
        "deliveries.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwpAtl2o7QWf"
      },
      "outputs": [],
      "source": [
        "deliveries.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDq1AuX-7SVZ"
      },
      "outputs": [],
      "source": [
        "deliveries.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc1b8c4z7U8D"
      },
      "outputs": [],
      "source": [
        "deliveries.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcKmpcdo7XbB"
      },
      "outputs": [],
      "source": [
        "deliveries.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6D1mIoH7ZiO"
      },
      "outputs": [],
      "source": [
        "deliveries.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UXXStOy7bj2"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        "    'Unnamed: 0', 'Match ID', 'Date', 'Venue',\n",
        "    'Bat First', 'Bat Second', 'Innings', 'Over', 'Ball', 'Winner', 'Chased Successfully',\n",
        "    'Non Striker', 'Total Non Striker Runs', 'Non Striker Balls Faced',\n",
        "    'Extra Runs', 'Extra Type', 'Ball Rebowled', 'Runs From Ball',\n",
        "    'Player Out', 'Method', 'Player Out Balls Faced', 'Player Out Runs',\n",
        "    'Innings Runs', 'Innings Wickets', 'Target Score', 'Runs to Get', 'Balls Remaining'\n",
        "]\n",
        "deliveries = deliveries.drop(columns=columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H7P0exn7eUx"
      },
      "outputs": [],
      "source": [
        "print(deliveries.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO6N_2tk7gug"
      },
      "outputs": [],
      "source": [
        "deliveries.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE9LNE9X7jLK"
      },
      "outputs": [],
      "source": [
        "\n",
        "batter_stats = deliveries.groupby('Batter').agg({\n",
        "    'Total Batter Runs': 'sum',\n",
        "    'Batter Balls Faced': 'sum'\n",
        "}).reset_index()\n",
        "batter_stats['Strike Rate'] = (batter_stats['Total Batter Runs'] / batter_stats['Batter Balls Faced']) * 100\n",
        "batter_stats = batter_stats.rename(columns={'Batter': 'Player'})\n",
        "balls_bowled_df = deliveries.groupby('Bowler').size().reset_index(name='Balls Bowled')\n",
        "balls_bowled_df['Overs Bowled'] = balls_bowled_df['Balls Bowled'] / 6\n",
        "balls_bowled_df = balls_bowled_df.rename(columns={'Bowler': 'Player'})\n",
        "bowler_stats = deliveries.groupby('Bowler').agg({\n",
        "    'Wicket': 'sum',\n",
        "    'Bowler Runs Conceded': 'sum'\n",
        "}).reset_index().rename(columns={'Bowler': 'Player'})\n",
        "bowler_stats = pd.merge(bowler_stats, balls_bowled_df, on='Player', how='left')\n",
        "bowler_stats['Economy Rate'] = bowler_stats['Bowler Runs Conceded'] / bowler_stats['Overs Bowled']\n",
        "player = pd.merge(batter_stats, bowler_stats, on='Player', how='outer')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7eMsnwx701p"
      },
      "outputs": [],
      "source": [
        "player.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S28FsFM7lUx"
      },
      "outputs": [],
      "source": [
        "def classify_balanced_v2(row):\n",
        "    # Batting thresholds\n",
        "    good_batter = row['Total Batter Runs'] >= 500 and row['Strike Rate'] >= 115\n",
        "    avg_batter = row['Total Batter Runs'] >= 200 and row['Strike Rate'] >= 105\n",
        "\n",
        "    # Bowling thresholds\n",
        "    is_bowler = row['Balls Bowled'] >= 150 and row['Wicket'] >= 3\n",
        "    good_bowler = row['Wicket'] >= 10 and row['Economy Rate'] <= 8.5 if is_bowler else False\n",
        "    avg_bowler = row['Wicket'] >= 5 and row['Economy Rate'] <= 9.5 if is_bowler else False\n",
        "\n",
        "\n",
        "    if good_batter:\n",
        "        return 'Good Batter'\n",
        "    elif good_bowler:\n",
        "        return 'Good Bowler'\n",
        "    elif (avg_batter) and (avg_bowler):\n",
        "        return 'All-Rounder'\n",
        "    elif avg_batter:\n",
        "        return 'Average Batter'\n",
        "    elif avg_bowler:\n",
        "        return 'Average Bowler'\n",
        "    else:\n",
        "        return 'Low Performer'\n",
        "\n",
        "player['Category'] = player.apply(classify_balanced_v2, axis=1)\n",
        "print(player['Category'].value_counts())\n",
        "print(player['Category'].value_counts(normalize=True) * 100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjHG6e_m76iW"
      },
      "outputs": [],
      "source": [
        "# Famous players to check\n",
        "famous_players = ['V Kohli', 'MS Dhoni']\n",
        "\n",
        "# Apply classification function if not already done\n",
        "player['Category'] = player.apply(classify_balanced_v2, axis=1)\n",
        "\n",
        "# Filter and display categories\n",
        "for name in famous_players:\n",
        "    result = player[player['Player'].str.lower() == name.lower()]\n",
        "    if not result.empty:\n",
        "        print(f\"{name}: {result['Category'].values[0]}\")\n",
        "    else:\n",
        "        print(f\"{name}: Not found in dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3RzO9BJ74m6"
      },
      "outputs": [],
      "source": [
        "print(player.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DIFyPXU79q4"
      },
      "outputs": [],
      "source": [
        "player.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvO0EzPj8Axa"
      },
      "outputs": [],
      "source": [
        "player = player.fillna(0)\n",
        "player = player[~np.isinf(player.select_dtypes(include=[np.number])).any(axis=1)].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zuZ31OD8DVO"
      },
      "outputs": [],
      "source": [
        "player.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBx6DnWO8F4n"
      },
      "outputs": [],
      "source": [
        "player.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz0-h1IN88wl"
      },
      "source": [
        "##EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRh2hMWj8IGS"
      },
      "outputs": [],
      "source": [
        "# Histograms for numerical features\n",
        "numeric_cols = player.select_dtypes(include=np.number).columns\n",
        "finite_cols = [col for col in numeric_cols if np.isfinite(player[col]).all()]\n",
        "player[finite_cols].hist(bins=30, figsize=(18, 15), color='skyblue')\n",
        "plt.suptitle(\"Histograms of Numerical Features\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRURtiv59CUN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Bar plots for categorical variables\n",
        "\n",
        "top_batters = player.sort_values(by='Total Batter Runs', ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='Player', y='Total Batter Runs', data=top_batters)\n",
        "plt.title(\"Top 10 Batters by Total Runs\")\n",
        "plt.xlabel(\"Player\")\n",
        "plt.ylabel(\"Total Runs\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfK9nCb89ApH"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "corr_matrix = player.select_dtypes(include=['float64', 'int64']).corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap of Numerical Features in Deliveries Dataset\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsGK1d2_9JDy"
      },
      "source": [
        "##Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgYfZujm9G03"
      },
      "outputs": [],
      "source": [
        "\n",
        "numeric_cols = player.select_dtypes(include='number').columns\n",
        "n_cols = 4\n",
        "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
        "\n",
        "plt.figure(figsize=(n_cols * 5, n_rows * 4))\n",
        "\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    sns.boxplot(y=player[col], color='skyblue')\n",
        "    plt.title(col)\n",
        "\n",
        "plt.suptitle(\"Boxplots for Numerical Columns in Player Dataset\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgLcyTvl9Onl"
      },
      "outputs": [],
      "source": [
        "def iqr_trim(s, k=1.5):\n",
        "    while True:\n",
        "        q1, q3 = s.quantile([0.25, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        lb, ub = q1 - k * iqr, q3 + k * iqr\n",
        "        new_s = s.where((s >= lb) & (s <= ub))\n",
        "        if new_s.equals(s):\n",
        "            return new_s.dropna()\n",
        "        s = new_s.dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5wJi7F5-hlY"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1c3WMym-iS0"
      },
      "source": [
        "##Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ2SRw7S9RvX"
      },
      "outputs": [],
      "source": [
        "player.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVoqGbNi-p0Y"
      },
      "outputs": [],
      "source": [
        "categorical_cols = player.select_dtypes(include='object').columns\n",
        "print(categorical_cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9TOduj--rxT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "player['Category_Label'] = LabelEncoder().fit_transform(player['Category'])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QyIAHos-trs"
      },
      "outputs": [],
      "source": [
        "player.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEBqO_t5-wq0"
      },
      "outputs": [],
      "source": [
        "player.describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPcHtyWY-0Ii"
      },
      "source": [
        "##Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAWklt3n-y0q"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "columns_to_scale = [\n",
        "    'Total Batter Runs', 'Batter Balls Faced', 'Strike Rate',\n",
        "    'Wicket', 'Bowler Runs Conceded', 'Balls Bowled',\n",
        "    'Overs Bowled', 'Economy Rate'\n",
        "]\n",
        "scaler = StandardScaler()\n",
        "scaled_values = scaler.fit_transform(player[columns_to_scale])\n",
        "scaled_df = pd.DataFrame(scaled_values, columns=columns_to_scale)\n",
        "player_scaled = pd.concat([player[['Player']], scaled_df, player[['Category','Category_Label']]], axis=1)\n",
        "player = player_scaled\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHxWHDaK-85b"
      },
      "outputs": [],
      "source": [
        "player.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70Q3vc_v-7B-"
      },
      "outputs": [],
      "source": [
        "player.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXfsmRBZ_C--"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_pBCLvd_BiL"
      },
      "outputs": [],
      "source": [
        "\n",
        "player = player.dropna()\n",
        "x = player.drop(columns=['Player', 'Category', 'Category_Label'], errors='ignore')\n",
        "y = player['Category_Label']\n",
        "print(\"x shape:\", x.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_A0NGSh_JTf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntKWvrzZ_M7C"
      },
      "source": [
        "###Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_s9vEck_LhV"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log=LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCFj_gZO_SgW"
      },
      "outputs": [],
      "source": [
        "model_log=log.fit(x_train,y_train)\n",
        "pred_log=model_log.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgva66BM_USK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_test, pred_log)\n",
        "precision = precision_score(y_test, pred_log, average='weighted')\n",
        "recall = recall_score(y_test, pred_log, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt9JfpQ6_Xv4"
      },
      "source": [
        "###KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8yJQXSo_WBf"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "x_train_sample = x_train.copy()\n",
        "y_train_sample = y_train.copy()\n",
        "\n",
        "metric_k = []\n",
        "neighbors = np.arange(3, 15)\n",
        "\n",
        "for k in neighbors:\n",
        "    k_model = KNeighborsClassifier(n_neighbors=k, metric='minkowski', n_jobs=-1)\n",
        "    k_model.fit(x_train_sample, y_train_sample)\n",
        "    y_pred = k_model.predict(x_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    metric_k.append(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k0XXQu-_a_U"
      },
      "outputs": [],
      "source": [
        "plt.plot(neighbors,metric_k,'o-')\n",
        "plt.xlabel('K value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N4y8kM2_cmn"
      },
      "outputs": [],
      "source": [
        "k_model=KNeighborsClassifier(n_neighbors=8,metric='minkowski')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuIt7DAN_f3a"
      },
      "outputs": [],
      "source": [
        " k_model.fit(x_train,y_train)\n",
        " y_pred=k_model.predict(x_test)\n",
        " acc=accuracy_score(y_test,y_pred)\n",
        " print(\"Accuracy\",acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI5D9HkZ_ixG"
      },
      "source": [
        "###SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV5ie-uz_hfB"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "svm_model = LinearSVC(max_iter=1000, dual=False)\n",
        "svm_model.fit(x_train, y_train)\n",
        "y_pred = svm_model.predict(x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHuH_egd_qfK"
      },
      "source": [
        "###Decccision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptVVG36N_o6f"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "dt_pred = model.predict(x_test)\n",
        "print(\"=== Decision Tree ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, dt_pred):.2f}\")\n",
        "print(f\"Precision (macro): {precision_score(y_test, dt_pred, average='macro'):.2f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, dt_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IuwiUUJ_47y"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bscnjZEr_2ye"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(x_train, y_train)\n",
        "rf_pred = model.predict(x_test)\n",
        "y_proba = model.predict_proba(x_test)\n",
        "\n",
        "print(\"=== Random Forest ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"Precision (macro):\", precision_score(y_test, rf_pred, average='macro'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, rf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChDPD3YbAGfX"
      },
      "source": [
        "###Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U-kYdgrAEj_"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(x_train, y_train)\n",
        "nb_pred = model.predict(x_test)\n",
        "y_proba = model.predict_proba(x_test)\n",
        "\n",
        "print(\"=== Naive Bayes ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, nb_pred))\n",
        "print(\"Precision (macro):\", precision_score(y_test, nb_pred, average='macro'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, nb_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVTx0YqLAM8y"
      },
      "source": [
        "###XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWsE4B7kALV-"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_model.fit(x_train, y_train)\n",
        "xgb_pred = xgb_model.predict(x_test)\n",
        "y_proba_xgb = xgb_model.predict_proba(x_test)\n",
        "print(\"=== XGBoost Classifier ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, xgb_pred))\n",
        "print(\"Precision (macro):\", precision_score(y_test, xgb_pred, average='macro'))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, xgb_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSaZhoHFASsj"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"KNN (k=8)\": KNeighborsClassifier(n_neighbors=8),\n",
        "    \"SVM\": LinearSVC(max_iter=1000, dual=False),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    results.append((name, acc, prec, rec))\n",
        "\n",
        "print(\"=== Model Comparison ===\")\n",
        "print(f\"{'Model':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10}\")\n",
        "for name, acc, prec, rec in results:\n",
        "    print(f\"{name:<20} {acc:<10.4f} {prec:<10.4f} {rec:<10.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqMGn2qAAarv"
      },
      "source": [
        "##Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WBJT4lTAi9C"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "dt_pred = models[\"Decision Tree\"].predict(x_test)\n",
        "xgb_pred = models[\"XGBoost\"].predict(x_test)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, dt_pred, ax=axs[0], cmap='Blues')\n",
        "axs[0].set_title(\"Decision Tree\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, xgb_pred, ax=axs[1], cmap='Oranges')\n",
        "axs[1].set_title(\"XGBoost\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW9xjW73AZ4e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "cv_scores = cross_val_score(xgb_model, x, y, cv=5)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean accuracy:\", cv_scores.mean())\n",
        "print(\"Standard deviation:\", cv_scores.std())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjYam95YAmy-"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "xgb_model.fit(x_train, y_train)\n",
        "xgb_pred = xgb_model.predict(x_test)\n",
        "print(\"=== XGBoost Classification Report ===\")\n",
        "print(classification_report(y_test, xgb_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvTRgT86Ar34"
      },
      "source": [
        "##HPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t50ud0KcAWl_"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'subsample': [0.8, 1],\n",
        "    'colsample_bytree': [0.8, 1]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYDEuKzvAwA-"
      },
      "outputs": [],
      "source": [
        "\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_search.fit(x_train, y_train)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maLAmhWcA10c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "y_best_pred = best_xgb_model.predict(x_test)\n",
        "accuracy_best = accuracy_score(y_test, y_best_pred)\n",
        "print(\"Best XGBoost Accuracy:\", accuracy_best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epuGlwA-A5aw"
      },
      "source": [
        "##Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahJ3sc7MA8UH"
      },
      "outputs": [],
      "source": [
        "\n",
        "new_player = pd.DataFrame([{\n",
        "    'Total Batter Runs': 560,\n",
        "    'Batter Balls Faced': 420,\n",
        "    'Strike Rate': 133.3,\n",
        "    'Wicket': 12,\n",
        "    'Bowler Runs Conceded': 350,\n",
        "    'Balls Bowled': 480,\n",
        "    'Overs Bowled': 80,\n",
        "    'Economy Rate': 7.0\n",
        "}])\n",
        "prediction = models[\"XGBoost\"].predict(new_player)\n",
        "label_map = {\n",
        "    0: \"All-Rounder\",\n",
        "    1: \"Average Batter\",\n",
        "    2: \"Average Bowler\",\n",
        "    3: \"Good Batter\",\n",
        "    4: \"Good Bowler\",\n",
        "    5: \"Low Performer\"\n",
        "}\n",
        "print(\"Predicted Label:\", label_map[prediction[0]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRgaJZ9tc4OE"
      },
      "source": [
        "##Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMkLxX3hc7XD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Step 1: Load and clean deliveries.csv\n",
        "deliveries = pd.read_csv(\"deliveries.csv\", on_bad_lines='skip', low_memory=False)\n",
        "deliveries.columns = deliveries.columns.str.strip()\n",
        "deliveries.fillna(0, inplace=True)\n",
        "\n",
        "# Step 2: Create derived features temporarily (used only for labeling, not as input)\n",
        "deliveries['Strike Rate'] = (deliveries['Total Batter Runs'] / deliveries['Batter Balls Faced'].replace(0, 1)) * 100\n",
        "deliveries['Economy Rate'] = (deliveries['Bowler Runs Conceded'] / deliveries['Valid Ball'].replace(0, 1)) * 6\n",
        "\n",
        "# Step 3: Define classification logic for labeling (used only here)\n",
        "def classify(row):\n",
        "    if row['Total Batter Runs'] >= 30 and row['Strike Rate'] >= 130:\n",
        "        return 'good batter'\n",
        "    elif row['Bowler Runs Conceded'] <= 25 and row['Economy Rate'] <= 6:\n",
        "        return 'good bowler'\n",
        "    else:\n",
        "        return 'average'\n",
        "\n",
        "# Create target label\n",
        "deliveries['performance_category'] = deliveries.apply(classify, axis=1)\n",
        "\n",
        "# Step 4: Define input features (excluding derived columns to force learning)\n",
        "features = ['Total Batter Runs', 'Batter Balls Faced', 'Bowler Runs Conceded', 'Valid Ball']\n",
        "X = deliveries[features]\n",
        "y = deliveries['performance_category']\n",
        "\n",
        "# Step 5: Encode target variable\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Step 6: Normalize input features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 7: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Build Neural Network model\n",
        "model = Sequential([\n",
        "    Dense(32, input_dim=X.shape[1], activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Step 9: Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9NHs7utc-e6"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nâœ… Deliveries.csv - Test Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPDQBTUCdDUW"
      },
      "source": [
        "#**Frontend**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit\n"
      ],
      "metadata": {
        "id": "z1cCLvNUY9VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "matches = pd.read_csv(\"matches.csv\")\n",
        "matches.fillna(\"Unknown\", inplace=True)\n",
        "columns_needed = [\n",
        "    'city', 'match_type', 'player_of_match', 'venue',\n",
        "    'toss_decision', 'umpire1', 'umpire2'\n",
        "]\n",
        "for col in columns_needed:\n",
        "    le = LabelEncoder()\n",
        "    matches[col] = le.fit_transform(matches[col])\n",
        "    joblib.dump(le, f\"{col}_encoder.pkl\")\n",
        "    print(f\"âœ… Saved: {col}_encoder.pkl\")\n"
      ],
      "metadata": {
        "id": "7ODN4tqA0i3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for team_col in ['team1', 'team2', 'toss_winner']:\n",
        "    le = LabelEncoder()\n",
        "    matches[team_col] = le.fit_transform(matches[team_col])\n",
        "    joblib.dump(le, f\"{team_col}_encoder.pkl\")\n",
        "    print(f\"âœ… Saved: {team_col}_encoder.pkl\")\n"
      ],
      "metadata": {
        "id": "5HXQ9iMt0rXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "id": "DsIKOPC10t9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv xgb_best_model.pkl ipl_model.pkl\n"
      ],
      "metadata": {
        "id": "1BhVgdii2yap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok --quiet\n"
      ],
      "metadata": {
        "id": "eDFFU_lW3qms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.express as px\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure page\n",
        "st.set_page_config(page_title=\"IPL Analytics Dashboard\", layout=\"wide\")\n",
        "st.title(\"ðŸ IPL Analytics Hub\")\n",
        "\n",
        "# Custom CSS\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .stAlert, .stWarning { display: none !important; }\n",
        "    .stException { border-left: 3px solid #ff2b2b !important; }\n",
        "    .stMarkdown { margin-bottom: 1rem; }\n",
        "    .stTabs [data-baseweb=\"tab-list\"] { gap: 10px; }\n",
        "    .stTabs [data-baseweb=\"tab\"] {\n",
        "        padding: 8px 16px;\n",
        "        border-radius: 4px 4px 0 0;\n",
        "        background: #f0f2f6;\n",
        "    }\n",
        "    .stTabs [aria-selected=\"true\"] {\n",
        "        background: white;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    [data-testid=\"stMetricValue\"] { font-size: 1.2rem; }\n",
        "    div[data-testid=\"stExpander\"] div[role=\"button\"] p {\n",
        "        font-size: 1.2rem;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: #f0f2f6;\n",
        "        padding: 15px;\n",
        "        border-radius: 10px;\n",
        "        margin-bottom: 15px;\n",
        "    }\n",
        "    .stDataFrame { width: 100%; }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Load data and models\n",
        "@st.cache_resource\n",
        "def load_assets():\n",
        "    assets = {\n",
        "        \"model\": None,\n",
        "        \"encoders\": {},\n",
        "        \"deliveries\": None,\n",
        "        \"matches\": None,\n",
        "        \"stacking_model\": None,\n",
        "        \"scaler\": None\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(\"ipl_model.pkl\"):\n",
        "            assets[\"model\"] = joblib.load(\"ipl_model.pkl\")\n",
        "        else:\n",
        "            st.warning(\"Model file 'ipl_model.pkl' not found. Match prediction will not be available.\")\n",
        "\n",
        "        encoder_files = {\n",
        "            \"city\": \"city_encoder.pkl\",\n",
        "            \"match_type\": \"match_type_encoder.pkl\",\n",
        "            \"player_of_match\": \"player_of_match_encoder.pkl\",\n",
        "            \"venue\": \"venue_encoder.pkl\",\n",
        "            \"team1\": \"team1_encoder.pkl\",\n",
        "            \"team2\": \"team2_encoder.pkl\",\n",
        "            \"toss_winner\": \"toss_winner_encoder.pkl\",\n",
        "            \"toss_decision\": \"toss_decision_encoder.pkl\",\n",
        "            \"winner\": \"winner_encoder.pkl\"\n",
        "        }\n",
        "\n",
        "        for name, file in encoder_files.items():\n",
        "            if os.path.exists(file):\n",
        "                assets[\"encoders\"][name] = joblib.load(file)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"âš  Model loading error: {str(e)}\")\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(\"matches.csv\"):\n",
        "            assets[\"matches\"] = pd.read_csv(\"matches.csv\")\n",
        "            # Ensure required columns exist\n",
        "            required_matches_cols = ['id', 'season', 'date', 'team1', 'team2', 'winner', 'city', 'venue']\n",
        "            for col in required_matches_cols:\n",
        "                if col not in assets[\"matches\"].columns:\n",
        "                    assets[\"matches\"][col] = np.nan\n",
        "            if 'date' in assets[\"matches\"].columns:\n",
        "                assets[\"matches\"]['date'] = pd.to_datetime(assets[\"matches\"]['date'], errors='coerce')\n",
        "        else:\n",
        "            st.error(\"Matches data file 'matches.csv' not found. Some features may be limited.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"âŒ Data loading error: {str(e)}\")\n",
        "\n",
        "    return assets\n",
        "\n",
        "assets = load_assets()\n",
        "\n",
        "# Create tabs\n",
        "tab1, tab2 = st.tabs([\"ðŸŽ¯ Match Predictor\", \"â­ Player Performance\"])\n",
        "\n",
        "# TAB 1: Match Predictor\n",
        "with tab1:\n",
        "    st.header(\"IPL Match Winner Predictor\")\n",
        "\n",
        "    if assets[\"model\"] is None:\n",
        "        st.error(\"âŒ Prediction model not available. Please ensure 'ipl_model.pkl' is in the same directory.\")\n",
        "    else:\n",
        "        form = st.form(\"prediction_form\")\n",
        "        with form:\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                # Season selection\n",
        "                if assets[\"matches\"] is not None and not assets[\"matches\"]['season'].isna().all():\n",
        "                    seasons = sorted(assets[\"matches\"]['season'].dropna().unique().tolist(), reverse=True)\n",
        "                else:\n",
        "                    seasons = list(range(2008, 2024))\n",
        "                season = st.selectbox(\"Season\", seasons, index=0)\n",
        "\n",
        "                # City selection\n",
        "                if \"city\" in assets[\"encoders\"]:\n",
        "                    cities = sorted(assets[\"encoders\"][\"city\"].classes_.tolist())\n",
        "                elif assets[\"matches\"] is not None and not assets[\"matches\"]['city'].isna().all():\n",
        "                    cities = sorted(assets[\"matches\"]['city'].dropna().unique().tolist())\n",
        "                else:\n",
        "                    cities = [\"Mumbai\", \"Chennai\", \"Kolkata\", \"Delhi\"]\n",
        "                city = st.selectbox(\"City\", cities, index=0)\n",
        "\n",
        "                # Match type - assuming fixed types if not encoded\n",
        "                match_types = [\"Group Stage\", \"Playoff\", \"Final\"]\n",
        "                if \"match_type\" in assets[\"encoders\"]:\n",
        "                    match_types = assets[\"encoders\"][\"match_type\"].classes_.tolist()\n",
        "                match_type = st.selectbox(\"Match Type\", match_types, index=0)\n",
        "\n",
        "                # Venue\n",
        "                if \"venue\" in assets[\"encoders\"]:\n",
        "                    venues = sorted(assets[\"encoders\"][\"venue\"].classes_.tolist())\n",
        "                elif assets[\"matches\"] is not None and not assets[\"matches\"]['venue'].isna().all():\n",
        "                    venues = sorted(assets[\"matches\"]['venue'].dropna().unique().tolist())\n",
        "                else:\n",
        "                    venues = [\"Wankhede Stadium\", \"Eden Gardens\", \"M. Chinnaswamy Stadium\"]\n",
        "                venue = st.selectbox(\"Venue\", venues, index=0)\n",
        "\n",
        "            with col2:\n",
        "                # Team selection\n",
        "                teams = []\n",
        "                if \"team1\" in assets[\"encoders\"]:\n",
        "                    teams = sorted(assets[\"encoders\"][\"team1\"].classes_.tolist())\n",
        "                elif assets[\"matches\"] is not None:\n",
        "                    teams = sorted(list(set(assets[\"matches\"]['team1'].dropna().unique()) | set(assets[\"matches\"]['team2'].dropna().unique())))\n",
        "                else:\n",
        "                    teams = [\"Chennai Super Kings\", \"Mumbai Indians\",\n",
        "                           \"Royal Challengers Bangalore\", \"Delhi Capitals\"]\n",
        "\n",
        "                team1 = st.selectbox(\"Team 1\", teams, index=0)\n",
        "                team2_options = [t for t in teams if t != team1]\n",
        "                team2 = st.selectbox(\"Team 2\", team2_options, index=min(1, len(team2_options)-1))\n",
        "\n",
        "                # Toss info\n",
        "                toss_winner = st.selectbox(\"Toss Winner\", [team1, team2], index=0)\n",
        "\n",
        "                toss_decisions = [\"bat\", \"field\"]\n",
        "                if \"toss_decision\" in assets[\"encoders\"]:\n",
        "                    toss_decisions = assets[\"encoders\"][\"toss_decision\"].classes_.tolist()\n",
        "                toss_decision = st.selectbox(\"Toss Decision\", toss_decisions, index=0)\n",
        "\n",
        "            submitted = form.form_submit_button(\"Predict Winner\", type=\"primary\")\n",
        "\n",
        "        if submitted:\n",
        "            with st.spinner(\"Analyzing match...\"):\n",
        "                try:\n",
        "                    # Prepare input data\n",
        "                    input_data = {\n",
        "                        \"season\": int(season),\n",
        "                        \"city\": city,\n",
        "                        \"match_type\": match_type,\n",
        "                        \"venue\": venue,\n",
        "                        \"team1\": team1,\n",
        "                        \"team2\": team2,\n",
        "                        \"toss_winner\": toss_winner,\n",
        "                        \"toss_decision\": toss_decision.lower(),\n",
        "                    }\n",
        "\n",
        "                    # Encode categorical features\n",
        "                    encoded_data = {}\n",
        "                    for feature in input_data:\n",
        "                        if feature in assets[\"encoders\"]:\n",
        "                            try:\n",
        "                                encoded_data[feature] = assets[\"encoders\"][feature].transform([input_data[feature]])[0]\n",
        "                            except ValueError:\n",
        "                                st.warning(f\"Category '{input_data[feature]}' for '{feature}' not seen during training. Using default value.\")\n",
        "                                encoded_data[feature] = 0\n",
        "                        else:\n",
        "                            encoded_data[feature] = input_data[feature]\n",
        "\n",
        "                    # Create DataFrame for prediction\n",
        "                    input_df = pd.DataFrame([encoded_data])\n",
        "\n",
        "                    if hasattr(assets[\"model\"], 'feature_names_in_'):\n",
        "                        missing_features = set(assets[\"model\"].feature_names_in_) - set(input_df.columns)\n",
        "                        for feature in missing_features:\n",
        "                            input_df[feature] = 0\n",
        "                        input_df = input_df[assets[\"model\"].feature_names_in_]\n",
        "                    else:\n",
        "                        st.warning(\"Model does not have 'feature_names_in_'. Assuming feature order is consistent.\")\n",
        "\n",
        "                    # Make prediction\n",
        "                    try:\n",
        "                        prediction = assets[\"model\"].predict(input_df)[0]\n",
        "\n",
        "                        # Determine winner based on prediction\n",
        "                        if isinstance(prediction, (int, float, np.integer)):\n",
        "                            winner = team1 if prediction == 0 else team2\n",
        "                        else:\n",
        "                            winner = str(prediction)\n",
        "\n",
        "                        # Get confidence score if available\n",
        "                        confidence = None\n",
        "                        if hasattr(assets[\"model\"], 'predict_proba'):\n",
        "                            proba = assets[\"model\"].predict_proba(input_df)[0]\n",
        "                            confidence = np.max(proba) * 100\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Prediction failed: {str(e)}\")\n",
        "                        winner = \"Prediction error\"\n",
        "                        confidence = None\n",
        "\n",
        "                    # Display results\n",
        "                    st.balloons()\n",
        "                    col1, col2 = st.columns(2)\n",
        "                    with col1:\n",
        "                        st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <h3>ðŸ† Predicted Winner</h3>\n",
        "                            <h2 style='color:#0068c9'>{winner}</h2>\n",
        "                        </div>\n",
        "                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                    if confidence is not None:\n",
        "                        with col2:\n",
        "                            st.markdown(f\"\"\"\n",
        "                            <div class=\"metric-card\">\n",
        "                                <h3>ðŸ“Š Confidence Score</h3>\n",
        "                                <h2 style='color:#0068c9'>{confidence:.1f}%</h2>\n",
        "                            </div>\n",
        "                            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                    if assets[\"matches\"] is not None:\n",
        "                        past_matches = assets[\"matches\"][\n",
        "                            ((assets[\"matches\"][\"team1\"] == team1) &\n",
        "                             (assets[\"matches\"][\"team2\"] == team2)) |\n",
        "                            ((assets[\"matches\"][\"team1\"] == team2) &\n",
        "                             (assets[\"matches\"][\"team2\"] == team1))\n",
        "                        ]\n",
        "                        if not past_matches.empty:\n",
        "                            team1_wins = len(past_matches[past_matches['winner'] == team1])\n",
        "                            team2_wins = len(past_matches[past_matches['winner'] == team2])\n",
        "                            st.write(f\"*Head-to-Head*: {team1} {team1_wins}-{team2_wins} {team2}\")\n",
        "                            st.subheader(\"Past Matches between these teams:\")\n",
        "                            st.dataframe(past_matches[['date', 'winner', 'result', 'venue']].sort_values('date', ascending=False))\n",
        "                        else:\n",
        "                            st.info(\"No past matches found between these two teams in the dataset.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"âŒ Processing failed: {str(e)}\")\n",
        "\n",
        "# TAB 2: Player Performance\n",
        "with tab2:\n",
        "    st.header(\"Player Performance Analyzer\")\n",
        "\n",
        "    # Simplified performance categories\n",
        "    performance_categories = {\n",
        "        0: \"â­ Emerging Player\",\n",
        "        1: \"ðŸ Specialist Batter\",\n",
        "        2: \"ðŸŽ¯ Specialist Bowler\",\n",
        "        3: \"ðŸŒŸ Star All-rounder\",\n",
        "        4: \"ðŸ’Ž Consistent Performer\",\n",
        "        5: \"ðŸ‘‘ Match Winner\"\n",
        "    }\n",
        "\n",
        "    # Create a simple form for player stats\n",
        "    with st.form(\"player_form\"):\n",
        "        st.subheader(\"Enter Player Statistics\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            batting_avg = st.number_input(\"Batting Average\", min_value=0.0, max_value=100.0, value=25.0)\n",
        "            strike_rate = st.number_input(\"Strike Rate\", min_value=0.0, max_value=200.0, value=120.0)\n",
        "            runs = st.number_input(\"Total Runs\", min_value=0, value=1000)\n",
        "            fifties = st.number_input(\"50s\", min_value=0, value=10)\n",
        "\n",
        "        with col2:\n",
        "            bowling_avg = st.number_input(\"Bowling Average\", min_value=0.0, max_value=100.0, value=30.0)\n",
        "            economy = st.number_input(\"Economy Rate\", min_value=0.0, max_value=15.0, value=7.5)\n",
        "            wickets = st.number_input(\"Total Wickets\", min_value=0, value=50)\n",
        "            best_figures = st.text_input(\"Best Bowling Figures\", value=\"3/20\")\n",
        "\n",
        "        submitted_player = st.form_submit_button(\"Analyze Performance\")\n",
        "\n",
        "    if submitted_player:\n",
        "        # Simple heuristic-based performance evaluation\n",
        "        batting_score = (batting_avg * strike_rate / 100) + (fifties * 5)\n",
        "        bowling_score = (100 - bowling_avg) * (10 - economy)\n",
        "        total_score = batting_score + bowling_score\n",
        "\n",
        "        if batting_score > 1500 and bowling_score > 1500:\n",
        "            category = 3  # Star All-rounder\n",
        "        elif batting_score > 2000:\n",
        "            if bowling_score > 500:\n",
        "                category = 4  # Consistent Performer\n",
        "            else:\n",
        "                category = 1  # Specialist Batter\n",
        "        elif bowling_score > 2000:\n",
        "            if batting_score > 500:\n",
        "                category = 4  # Consistent Performer\n",
        "            else:\n",
        "                category = 2  # Specialist Bowler\n",
        "        elif total_score > 2000:\n",
        "            category = 5  # Match Winner\n",
        "        else:\n",
        "            category = 0  # Emerging Player\n",
        "\n",
        "        st.success(f\"### Performance Category: {performance_categories[category]}\")\n",
        "\n",
        "        # Show some insights\n",
        "        with st.expander(\"Performance Insights\"):\n",
        "            st.write(f\"**Batting Score:** {batting_score:.1f} (Average: {batting_avg}, SR: {strike_rate})\")\n",
        "            st.write(f\"**Bowling Score:** {bowling_score:.1f} (Average: {bowling_avg}, Economy: {economy})\")\n",
        "\n",
        "            if category == 0:\n",
        "                st.info(\"This player shows potential but needs more experience to become a consistent performer.\")\n",
        "            elif category == 1:\n",
        "                st.info(\"A reliable batter who can anchor the innings or accelerate as needed.\")\n",
        "            elif category == 2:\n",
        "                st.info(\"A wicket-taking bowler who can bowl economically in pressure situations.\")\n",
        "            elif category == 3:\n",
        "                st.info(\"A rare all-round talent who contributes significantly with both bat and ball.\")\n",
        "            elif category == 4:\n",
        "                st.info(\"A dependable player who performs consistently across matches.\")\n",
        "            else:\n",
        "                st.info(\"A match-winner who can single-handedly change the course of the game.\")\n",
        "\n",
        "        # Simple visualization\n",
        "        data = {\n",
        "            'Metric': ['Batting', 'Bowling', 'Overall'],\n",
        "            'Score': [batting_score, bowling_score, total_score]\n",
        "        }\n",
        "        fig = px.bar(data, x='Metric', y='Score', title='Performance Breakdown')\n",
        "        st.plotly_chart(fig, use_container_width=True)"
      ],
      "metadata": {
        "id": "5EYQtaKa5bS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ngrok config add-authtoken <YOUR TOKEN>"
      ],
      "metadata": {
        "id": "FmsDIAwV4KZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "\n",
        "def run():\n",
        "    os.system(\"streamlit run app.py\")\n",
        "\n",
        "thread = threading.Thread(target=run)\n",
        "thread.start()\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸŒ Streamlit app is live at:\", public_url)\n"
      ],
      "metadata": {
        "id": "HXEVIePa32JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSngULy7d_Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "49oGS5bNMLJC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7hRbxNRFeQIf",
        "Z8bgCDuDeV7p",
        "KxVNdmu4fPEh",
        "Y4-qbjNLfe3n",
        "PZRXDFKefuMm",
        "Nz4IYV0oge7u",
        "kvUg3H_WiWiO",
        "SwqQa-P8k9Xb",
        "cTnsw7G4lNxg",
        "YzLf3eB-ldqO",
        "YqhoooP36NTr",
        "kZ4AQRbI60Tg",
        "Zz0-h1IN88wl",
        "EsGK1d2_9JDy",
        "w1c3WMym-iS0",
        "wPcHtyWY-0Ii",
        "uXfsmRBZ_C--",
        "OqMGn2qAAarv",
        "KvTRgT86Ar34",
        "epuGlwA-A5aw",
        "rRgaJZ9tc4OE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}